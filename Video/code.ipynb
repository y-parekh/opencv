{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7etU26SSPXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.0\n",
        "import face_recognition\n",
        "import cv2\n",
        "\n",
        "# This code implements face recognition on a video(input.mp4)\n",
        "# and saves the result in a new video file(output.avi)\n",
        "\n",
        "# 2.1\n",
        "# Opening the input\n",
        "input_video = cv2.VideoCapture(\"input1.mp4\")\n",
        "length = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# 2.2\n",
        "# Creating the output file with specifications same as input file\n",
        "fourcc = cv2.VideoWriter_fourcc('M','P','E','G')\n",
        "output_video = cv2.VideoWriter('output.avi', fourcc, 23.976024, (1280, 538))\n",
        "\n",
        "# 2.3\n",
        "# Providing sample images to learn how to recognize them\n",
        "image1 = face_recognition.load_image_file(\"ryan.jpeg\")\n",
        "image1_encoding = face_recognition.face_encodings(image1)[0]\n",
        "image2 = face_recognition.load_image_file(\"steve.jpeg\")\n",
        "image2_encoding = face_recognition.face_encodings(image2)[0]\n",
        "\n",
        "# 2.4\n",
        "# Initializing an array of known faces and other variables\n",
        "known_faces = [\n",
        "    image1_encoding,\n",
        "    image2_encoding\n",
        "]\n",
        "\n",
        "face_locations = []\n",
        "face_encodings = []\n",
        "face_names = []\n",
        "frame_number = 0\n",
        "\n",
        "# 2.5\n",
        "# Implementing face detection and recognition logic frame by frame\n",
        "while True:\n",
        "    # Selecting one frame of the video\n",
        "    ret, frame = input_video.read()\n",
        "    frame_number += 1\n",
        "\n",
        "    # Stop at End Of File(Video)\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # OpenCV uses BGR color, converting it to RGB color used by face_recognition\n",
        "    rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "    # Detecting all the faces in the current frame\n",
        "    face_locations = face_recognition.face_locations(rgb_frame)\n",
        "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "    # Checking if face matches to a known face and adding to list\n",
        "    face_names = []\n",
        "    for face_encoding in face_encodings:\n",
        "        check = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)\n",
        "\n",
        "        name = None\n",
        "        if check[0]:\n",
        "            name = \"Ryan\"\n",
        "        elif check[1]:\n",
        "            name = \"Steve\"\n",
        "        else:\n",
        "          name = \"Unknown\"\n",
        "\n",
        "        face_names.append(name)\n",
        "\n",
        "    # Labeling the results\n",
        "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
        "        if not name:\n",
        "            continue\n",
        "\n",
        "        # Draw a box around the face\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "\n",
        "        # Write the label(Name of person) below the face\n",
        "        cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "    # Writing the resulting image to the output video\n",
        "    print(\"Writing frame {} / {}\".format(frame_number, length))\n",
        "    output_video.write(frame)\n",
        "\n",
        "# 2.6\n",
        "# Releasing the memory\n",
        "input_video.release()\n",
        "\n",
        "# Done!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLu802tRS8wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}